
<p align="center">
  <img src="images/logo.png" width=250>
</p>

<p align="center">

  <a href="https://github.com/hb-research/notes">
    <img src="https://img.shields.io/badge/DeepLearning-Notes-brightgreen.svg" alt="Project Introduction">
  </a>
  
  <a href="https://github.com/hb-research/notes">
    <img src="https://img.shields.io/badge/Summary-Code-brightgreen.svg" alt="Project Introduction">
  </a>

</p>

# notes: Notes of Deep Learning 

## Category 

- [Optimization](#optimization)
- [Unsupervised & Generative](#unsupervised-&-generative)
- [Computer Vision](#computer-vision)
- [Natural Language Processing](#natural-language-processing)
- [Speech](#speech)
- [Reinforcement](reinforcement)

---

- Deep Learning (2015) ****`Review`****
	- [nature](http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf) | [notes](notes/deep_learning.md)

## Unsupervised & Generative

- Auto-Encoding Variational Bayes (2013, 12) ****`Generative`****, ****`Approximate`****
	 - [arXiv](https://arxiv.org/abs/1312.6114) | [notes](notes/vae.md)

## Optimization

- Dropout (2012, 2014) ****`Regulaizer`****, ****`Ensemble`****
	- [arXiv (2012)](https://arxiv.org/pdf/1207.0580.pdf) | [arXiv (2014)](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf) | [notes](notes/dropout.md)

## NLP

- Attention Is All You Need (2017. 6) ****`Attention`****
	- [arXiv](https://arxiv.org/pdf/1706.03762.pdf) | [notes](notes/transformer.md) | [codes](https://github.com/DongjunLee/transformer-tensorflow)  